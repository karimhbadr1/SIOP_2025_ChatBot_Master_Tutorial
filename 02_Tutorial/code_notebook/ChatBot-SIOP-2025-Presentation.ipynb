{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee34e4d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First, install the necessary packages\n",
    "# Run this cell first if you're setting up a new environment\n",
    "\n",
    "!pip install -U langchain langchain-openai langchain-community faiss-cpu pypdf unstructured pandas openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# Set up OpenAI API key - either from environment variable or enter\n",
    "if not os.getenv(\"openai_api_key\"):\n",
    "    os.environ[\"openai_api_key\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "openai_api_key = os.getenv(\"openai_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader, UnstructuredMarkdownLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0451c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_papers(papers_folder, docformat=\"pdf\"):\n",
    "    \"\"\"\n",
    "    Read all papers from a folder and load their content.\n",
    "    \n",
    "    Args:\n",
    "        papers_folder: Path to the folder containing papers\n",
    "        docformat: Format of documents ('pdf' or 'md')\n",
    "    \n",
    "    Returns:\n",
    "        List of all pages from all papers\n",
    "    \"\"\"\n",
    "    # Get list of all papers in the folder\n",
    "    papers = [x for x in os.listdir(papers_folder)]\n",
    "    all_pages = []\n",
    "    \n",
    "    if docformat == \"pdf\":\n",
    "        # For PDF files\n",
    "        paper_page = []\n",
    "        for x in papers:\n",
    "            try:\n",
    "                # Load and split each PDF file\n",
    "                loader = PyPDFLoader(os.path.join(papers_folder, x))\n",
    "                pages = loader.load_and_split()\n",
    "                paper_page.append(pages)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {x}: {e}\")\n",
    "        # Flatten all pages into a single list\n",
    "        all_pages = [item for sublist in paper_page for item in sublist]\n",
    "    \n",
    "    elif docformat == \"md\":\n",
    "        # For Markdown files\n",
    "        paper_page = []\n",
    "        for x in papers:\n",
    "            try:\n",
    "                # Load each Markdown file\n",
    "                loader = UnstructuredMarkdownLoader(os.path.join(papers_folder, x))\n",
    "                pages = loader.load()\n",
    "                paper_page.append(pages)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {x}: {e}\")\n",
    "        all_pages = [x[0] for x in paper_page]\n",
    "    \n",
    "    # Create a DataFrame to display paper information\n",
    "    df_papers = pd.DataFrame({\"Paper\": papers, \"Page\": [len(x) for x in paper_page]})\n",
    "    display(df_papers)\n",
    "    print(f\"Total {len(df_papers)} Papers with {sum(df_papers['Page'])} Pages are read\")\n",
    "    \n",
    "    return all_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cad7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_papers(all_pages, chunk_size=4096, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Split paper content into smaller chunks for better processing.\n",
    "    \n",
    "    Args:\n",
    "        all_pages: List of document pages\n",
    "        chunk_size: Maximum size of each chunk\n",
    "        chunk_overlap: Overlap between chunks to maintain context\n",
    "    \n",
    "    Returns:\n",
    "        List of chunked text documents\n",
    "    \"\"\"\n",
    "    # Create a text splitter with specified parameters\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "    )\n",
    "    \n",
    "    # Combine all text and remove line breaks\n",
    "    combined_text = \" \".join([x.page_content.replace('\\n', '') for x in all_pages])\n",
    "    \n",
    "    # Split the combined text into chunks\n",
    "    chunked_texts = text_splitter.create_documents([combined_text])\n",
    "    \n",
    "    return chunked_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7152f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_papers_df(chunked_texts):\n",
    "    \"\"\"\n",
    "    Create a DataFrame from chunked texts for easy viewing.\n",
    "    This is just for display, not used for retrieval.\n",
    "    \n",
    "    Args:\n",
    "        chunked_texts: List of chunked text documents\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame containing chunked texts and their lengths\n",
    "    \"\"\"\n",
    "    # Extract text content from documents\n",
    "    chunked_texts = [x.page_content for x in chunked_texts]\n",
    "    \n",
    "    # Create DataFrame and remove duplicates\n",
    "    df_chunks = pd.DataFrame({\"chunked_text\": chunked_texts})\n",
    "    df_chunks = df_chunks.drop_duplicates(subset=['chunked_text'], keep='first')\n",
    "    \n",
    "    # Calculate length of each chunk\n",
    "    df_chunks['length'] = df_chunks['chunked_text'].apply(lambda x: len(x))\n",
    "    \n",
    "    return df_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6206e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_embeddings(df, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"\n",
    "    Generate embeddings for chunked text using OpenAI.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing 'chunked_text' column\n",
    "        model: The embedding model to use\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with added 'embeddings' column\n",
    "    \"\"\"\n",
    "    # Initialize the OpenAI embeddings model\n",
    "    embeddings_model = OpenAIEmbeddings(\n",
    "        model=model,\n",
    "        openai_api_key=openai_api_key\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Generate embeddings for all chunks\n",
    "        embedding_vectors = embeddings_model.embed_documents(df['chunked_text'].tolist())\n",
    "        \n",
    "        # Add embeddings to the DataFrame\n",
    "        df[\"embeddings\"] = embedding_vectors\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embeddings: {e}\")\n",
    "        return None\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081efc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_vector_database(chunked_texts):\n",
    "    \"\"\"\n",
    "    Create and configure a FAISS vector database for document retrieval.\n",
    "    \n",
    "    Args:\n",
    "        chunked_texts: List of chunked text documents\n",
    "    \n",
    "    Returns:\n",
    "        Configured retriever object\n",
    "    \"\"\"\n",
    "    # Initialize the OpenAI embeddings model\n",
    "    embeddings_model = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "    \n",
    "    # Create a FAISS vector store from documents\n",
    "    vectorstore = FAISS.from_documents(chunked_texts, embeddings_model)\n",
    "    \n",
    "    # Save the vector store locally for future use\n",
    "    vectorstore.save_local(\"siop_demo_code_assessment_db_siop_principles.db\")\n",
    "    \n",
    "    # Create a retriever from the vector store\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "    \n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef13c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_similar_question(question):\n",
    "    \"\"\"\n",
    "    Generate a similar but differently worded question using GPT-4o.\n",
    "    \n",
    "    Args:\n",
    "        question: Original user question\n",
    "    \n",
    "    Returns:\n",
    "        Similar question with different wording\n",
    "    \"\"\"\n",
    "    # Initialize ChatGPT model\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0.7,  # Some creativity for variation\n",
    "        model_name=\"gpt-4o\",\n",
    "        openai_api_key=openai_api_key\n",
    "    )\n",
    "    \n",
    "    # Prompt to generate similar question\n",
    "    prompt = f\"\"\"\n",
    "    Generate a question that is similar to but worded differently from this one: \n",
    "    '{question}'\n",
    "    \n",
    "    Return only the reworded question without any explanations or quotation marks.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate the similar question\n",
    "    similar_question = llm.invoke(prompt)\n",
    "    \n",
    "    # Extract the text content from the response\n",
    "    if hasattr(similar_question, 'content'):\n",
    "        return similar_question.content.strip()\n",
    "    return similar_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e30c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_retrieval(question, retriever):\n",
    "    \"\"\"\n",
    "    Enhance retrieval by using both the original question and a similar question.\n",
    "    \n",
    "    Args:\n",
    "        question: Original user question\n",
    "        retriever: Document retriever\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing combined documents and retrieval details\n",
    "    \"\"\"\n",
    "    # Generate a similar question\n",
    "    similar_question = generate_similar_question(question)\n",
    "    print(f\"Original question: {question}\")\n",
    "    print(f\"Similar question: {similar_question}\")\n",
    "    \n",
    "    # Retrieve documents for original question (top 2)\n",
    "    original_docs = retriever.invoke(question)[:2]\n",
    "    \n",
    "    # Retrieve documents for similar question (top 2)\n",
    "    similar_docs = retriever.invoke(similar_question)[:2]\n",
    "    \n",
    "    # Track which documents came from which query\n",
    "    original_contents = [doc.page_content for doc in original_docs]\n",
    "    similar_contents = [doc.page_content for doc in similar_docs]\n",
    "    \n",
    "    # Find overlapping documents (appearing in both searches)\n",
    "    overlapping_contents = set(original_contents) & set(similar_contents)\n",
    "    \n",
    "    # Combine results (removing duplicates)\n",
    "    combined_docs = []\n",
    "    seen_contents = set()\n",
    "    \n",
    "    for doc in original_docs + similar_docs:\n",
    "        if doc.page_content not in seen_contents:\n",
    "            combined_docs.append(doc)\n",
    "            seen_contents.add(doc.page_content)\n",
    "    \n",
    "    # Return as a dictionary with all the information\n",
    "    return {\n",
    "        \"combined_docs\": combined_docs,\n",
    "        \"original_docs\": original_docs,\n",
    "        \"similar_docs\": similar_docs,\n",
    "        \"overlapping_contents\": overlapping_contents\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1f4207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_chain():\n",
    "    \"\"\"\n",
    "    Create a modern LangChain QA chain using the latest patterns.\n",
    "    \n",
    "    Returns:\n",
    "        A runnable QA chain\n",
    "    \"\"\"\n",
    "    # Initialize the ChatGPT model\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0,  # Deterministic output\n",
    "        model_name=\"gpt-4o\",\n",
    "        openai_api_key=openai_api_key\n",
    "    )\n",
    "    \n",
    "    # Create the prompt template\n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "    You act as a helpful question answer assistant. \n",
    "    Given the following context as information source, answer any questions. \n",
    "    Always answer in two sections.\n",
    "\n",
    "    Generate a concise answer from the given context as information source or mention that the source does not contain relevant information\n",
    "\n",
    "    If you can't find the answer in the context below, just say \"I'm not sure.\" Don't try to make up an answer.\n",
    "    If the context or question is R codes, explain very details of these R codes.\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Always answer in Markdown format:\n",
    "    \"\"\")\n",
    "    \n",
    "    # Create the QA chain using modern LangChain patterns\n",
    "    qa_chain = (\n",
    "        {\"context\": lambda input_dict: \"\\n\\n\".join([doc.page_content for doc in input_dict[\"documents\"]]),\n",
    "         \"question\": lambda input_dict: input_dict[\"question\"]}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d46ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_chunk_display(doc, is_overlapping=False, max_length=200):\n",
    "    \"\"\"\n",
    "    Format a document chunk for display with proper highlighting.\n",
    "    \n",
    "    Args:\n",
    "        doc: The document to format\n",
    "        is_overlapping: Whether this chunk appears in both searches\n",
    "        max_length: Maximum length to display before truncating\n",
    "    \n",
    "    Returns:\n",
    "        Formatted HTML string for the chunk\n",
    "    \"\"\"\n",
    "    from IPython.display import HTML\n",
    "    \n",
    "    overlap_style = \"background-color: #fff3cd; padding: 5px; border-left: 3px solid #ffc107;\" if is_overlapping else \"\"\n",
    "    content = doc.page_content\n",
    "    \n",
    "    # Truncate if needed\n",
    "    if len(content) > max_length:\n",
    "        displayed_content = content[:max_length] + \"...\"\n",
    "    else:\n",
    "        displayed_content = content\n",
    "    \n",
    "    # Escape HTML characters\n",
    "    import html\n",
    "    displayed_content = html.escape(displayed_content)\n",
    "    \n",
    "    # Format with styling\n",
    "    return f\"<div style='margin-bottom: 10px; padding: 10px; border: 1px solid #ddd; border-radius: 5px; {overlap_style}'>{displayed_content}</div>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87bcbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_retrieval_results(retrieval_result):\n",
    "    \"\"\"\n",
    "    Display the retrieval results in a more visual format.\n",
    "    \n",
    "    Args:\n",
    "        retrieval_result: Dictionary containing retrieval details\n",
    "    \"\"\"\n",
    "    from IPython.display import display, HTML\n",
    "    \n",
    "    # Safety check for backward compatibility\n",
    "    if not isinstance(retrieval_result, dict):\n",
    "        print(\"Unable to display results in visual format. Using text format instead.\")\n",
    "        print(\"\\n==== Retrieved Chunks ====\\n\")\n",
    "        for i, doc in enumerate(retrieval_result):\n",
    "            truncated_content = doc.page_content[:200] + \"...\" if len(doc.page_content) > 200 else doc.page_content\n",
    "            print(f\"* Chunk {i+1}: {truncated_content}\\n\")\n",
    "        return\n",
    "    \n",
    "    html_content = \"\"\"\n",
    "    <style>\n",
    "    .chunk-container {\n",
    "        margin-bottom: 20px;\n",
    "    }\n",
    "    .chunk-header {\n",
    "        font-weight: bold;\n",
    "        margin-bottom: 10px;\n",
    "        padding: 5px;\n",
    "        background-color: #f8f9fa;\n",
    "    }\n",
    "    .overlap-note {\n",
    "        font-style: italic;\n",
    "        color: #856404;\n",
    "        background-color: #fff3cd;\n",
    "        padding: 3px 6px;\n",
    "        border-radius: 3px;\n",
    "        margin-left: 5px;\n",
    "    }\n",
    "    .summary-box {\n",
    "        background-color: #e9ecef;\n",
    "        padding: 10px;\n",
    "        border-radius: 5px;\n",
    "        margin-top: 20px;\n",
    "        margin-bottom: 20px;\n",
    "    }\n",
    "    </style>\n",
    "    \n",
    "    <h3>Retrieved Chunks</h3>\n",
    "    \n",
    "    <div class=\"chunk-container\">\n",
    "        <div class=\"chunk-header\">Chunks from ORIGINAL question:</div>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add original chunks\n",
    "    for i, doc in enumerate(retrieval_result[\"original_docs\"]):\n",
    "        is_overlapping = doc.page_content in retrieval_result[\"overlapping_contents\"]\n",
    "        overlap_mark = \"<span class='overlap-note'>OVERLAP</span>\" if is_overlapping else \"\"\n",
    "        html_content += f\"<div><strong>Chunk {i+1}</strong> {overlap_mark}</div>\"\n",
    "        html_content += format_chunk_display(doc, is_overlapping)\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "    <div class=\"chunk-container\">\n",
    "        <div class=\"chunk-header\">Chunks from SIMILAR question:</div>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add similar chunks\n",
    "    for i, doc in enumerate(retrieval_result[\"similar_docs\"]):\n",
    "        is_overlapping = doc.page_content in retrieval_result[\"overlapping_contents\"]\n",
    "        overlap_mark = \"<span class='overlap-note'>OVERLAP</span>\" if is_overlapping else \"\"\n",
    "        html_content += f\"<div><strong>Chunk {i+1}</strong> {overlap_mark}</div>\"\n",
    "        html_content += format_chunk_display(doc, is_overlapping)\n",
    "    \n",
    "    # Add summary\n",
    "    html_content += f\"\"\"\n",
    "    <div class=\"summary-box\">\n",
    "        <strong>Summary:</strong><br>\n",
    "        Found {len(retrieval_result['original_docs'])} chunks from original question, \n",
    "        {len(retrieval_result['similar_docs'])} chunks from similar question, \n",
    "        with {len(retrieval_result['overlapping_contents'])} overlapping chunks.<br>\n",
    "        Combined unique chunks for answer generation: {len(retrieval_result['combined_docs'])}\n",
    "    </div>\n",
    "    \n",
    "    <h3>Answer</h3>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f962e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(question, show_chunks=True, visual_display=True):\n",
    "    \"\"\"\n",
    "    Ask a question and get an answer using our enhanced RAG system.\n",
    "    \n",
    "    Args:\n",
    "        question: The user's question\n",
    "        show_chunks: Whether to display the retrieved chunks (default: True)\n",
    "        visual_display: Use visual HTML display for chunks (default: True)\n",
    "    \n",
    "    Returns:\n",
    "        String containing the answer (can be displayed with Markdown())\n",
    "    \"\"\"\n",
    "    # Get relevant documents using enhanced retrieval\n",
    "    retrieval_result = enhanced_retrieval(question, retriever)\n",
    "    \n",
    "    # Handle both dictionary and list return types for backward compatibility\n",
    "    if isinstance(retrieval_result, dict):\n",
    "        combined_docs = retrieval_result[\"combined_docs\"]\n",
    "    else:\n",
    "        # If retrieval_result is a list, it's the old format returning just combined_docs\n",
    "        combined_docs = retrieval_result\n",
    "        # Create a simplified dictionary for compatibility\n",
    "        retrieval_result = {\n",
    "            \"combined_docs\": combined_docs,\n",
    "            \"original_docs\": combined_docs[:1],  # Simplification\n",
    "            \"similar_docs\": combined_docs[1:] if len(combined_docs) > 1 else [],\n",
    "            \"overlapping_contents\": set()\n",
    "        }\n",
    "    \n",
    "    # Display the chunks if requested\n",
    "    if show_chunks:\n",
    "        if visual_display:\n",
    "            # Use the visual HTML display\n",
    "            display_retrieval_results(retrieval_result)\n",
    "        else:\n",
    "            # Use plain text display\n",
    "            print(\"\\n==== Retrieved Chunks ====\\n\")\n",
    "            \n",
    "            # Display chunks from original question\n",
    "            print(\"Chunks from ORIGINAL question:\")\n",
    "            for i, doc in enumerate(retrieval_result[\"original_docs\"]):\n",
    "                is_overlapping = doc.page_content in retrieval_result[\"overlapping_contents\"]\n",
    "                overlap_mark = \"* [OVERLAP] \" if is_overlapping else \"* \"\n",
    "                truncated_content = doc.page_content[:200] + \"...\" if len(doc.page_content) > 200 else doc.page_content\n",
    "                print(f\"{overlap_mark}Chunk {i+1}: {truncated_content}\\n\")\n",
    "            \n",
    "            # Display chunks from similar question\n",
    "            print(\"\\nChunks from SIMILAR question:\")\n",
    "            for i, doc in enumerate(retrieval_result[\"similar_docs\"]):\n",
    "                is_overlapping = doc.page_content in retrieval_result[\"overlapping_contents\"]\n",
    "                overlap_mark = \"* [OVERLAP] \" if is_overlapping else \"* \"\n",
    "                truncated_content = doc.page_content[:200] + \"...\" if len(doc.page_content) > 200 else doc.page_content\n",
    "                print(f\"{overlap_mark}Chunk {i+1}: {truncated_content}\\n\")\n",
    "            \n",
    "            # Summary\n",
    "            print(f\"\\nSummary: Found {len(retrieval_result['original_docs'])} chunks from original question, \" + \n",
    "                  f\"{len(retrieval_result['similar_docs'])} chunks from similar question, \" +\n",
    "                  f\"with {len(retrieval_result['overlapping_contents'])} overlapping chunks\")\n",
    "            print(f\"Combined unique chunks for answer generation: {len(combined_docs)}\")\n",
    "            print(\"\\n==== Answer ====\\n\")\n",
    "    \n",
    "    # Create and use the QA chain\n",
    "    qa_chain = create_qa_chain()\n",
    "    answer = qa_chain.invoke({\"documents\": combined_docs, \"question\": question})\n",
    "    \n",
    "    # Return the answer as a string (not wrapped in Markdown)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b932b8ba",
   "metadata": {},
   "source": [
    "Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ebcf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Create file directory if it doesn't exist, e.g. SIOP Principles\n",
    "principles_dir = './Principles/'\n",
    "if not os.path.exists(principles_dir):\n",
    "    os.makedirs(principles_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec6adae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read papers\n",
    "all_papers = read_papers('./Principles/')\n",
    "all_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6bc1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Chunk papers into segments\n",
    "chunked_texts = chunk_papers(all_papers, chunk_size=1000, chunk_overlap=200)\n",
    "df_chunks = chunk_papers_df(chunked_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4199fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46695a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Generate embeddings (optional display step)\n",
    "df_with_embeddings = get_openai_embeddings(df_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eec8815",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee05df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Setup vector database\n",
    "retriever = setup_vector_database(chunked_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f31f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Ask questions\n",
    "display(Markdown(ask(\"tell me about the Generalizing Validity Evidence\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "karim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
